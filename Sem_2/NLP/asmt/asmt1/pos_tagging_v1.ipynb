{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-08T19:48:52.501221200Z",
     "start_time": "2024-01-08T19:48:51.039037300Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\praka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\praka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\praka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\praka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package tagsets to\n",
      "[nltk_data]     C:\\Users\\praka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package tagsets is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "import re\n",
    "import random\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('tagsets')\n",
    "from nltk.corpus import reuters, stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from nltk import bigrams, FreqDist, ConditionalFreqDist\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1048309, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                             reviews       reviewers  \\\n0  Pretty dry, but I was able to pass with just t...     By Robert S   \n1  would be a better experience if the video and ...  By Gabriel E R   \n2  Information was perfect! The program itself wa...      By Jacob D   \n3  A few grammatical mistakes on test made me do ...       By Dale B   \n4  Excellent course and the training provided was...       By Sean G   \n\n   date_reviews  rating                 course_id  \n0  Feb 12, 2020     4.0  google-cbrs-cpi-training  \n1  Sep 28, 2020     4.0  google-cbrs-cpi-training  \n2  Apr 08, 2020     4.0  google-cbrs-cpi-training  \n3  Feb 24, 2020     4.0  google-cbrs-cpi-training  \n4  Jun 18, 2020     4.0  google-cbrs-cpi-training  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>reviews</th>\n      <th>reviewers</th>\n      <th>date_reviews</th>\n      <th>rating</th>\n      <th>course_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Pretty dry, but I was able to pass with just t...</td>\n      <td>By Robert S</td>\n      <td>Feb 12, 2020</td>\n      <td>4.0</td>\n      <td>google-cbrs-cpi-training</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>would be a better experience if the video and ...</td>\n      <td>By Gabriel E R</td>\n      <td>Sep 28, 2020</td>\n      <td>4.0</td>\n      <td>google-cbrs-cpi-training</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Information was perfect! The program itself wa...</td>\n      <td>By Jacob D</td>\n      <td>Apr 08, 2020</td>\n      <td>4.0</td>\n      <td>google-cbrs-cpi-training</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A few grammatical mistakes on test made me do ...</td>\n      <td>By Dale B</td>\n      <td>Feb 24, 2020</td>\n      <td>4.0</td>\n      <td>google-cbrs-cpi-training</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Excellent course and the training provided was...</td>\n      <td>By Sean G</td>\n      <td>Jun 18, 2020</td>\n      <td>4.0</td>\n      <td>google-cbrs-cpi-training</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Coursera_reviews.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T19:48:54.792130500Z",
     "start_time": "2024-01-08T19:48:52.502629900Z"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "1. Preprocess the dataset to convert it into a format that the algorithm can work with.\n",
    "\n",
    "-- depends on algo, reiterate on it basis requirement"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "                                             reviews       reviewers  \\\n0  Pretty dry, but I was able to pass with just t...     By Robert S   \n1  would be a better experience if the video and ...  By Gabriel E R   \n2  Information was perfect! The program itself wa...      By Jacob D   \n3  A few grammatical mistakes on test made me do ...       By Dale B   \n4  Excellent course and the training provided was...       By Sean G   \n\n   date_reviews  rating                 course_id  \n0  Feb 12, 2020     4.0  google-cbrs-cpi-training  \n1  Sep 28, 2020     4.0  google-cbrs-cpi-training  \n2  Apr 08, 2020     4.0  google-cbrs-cpi-training  \n3  Feb 24, 2020     4.0  google-cbrs-cpi-training  \n4  Jun 18, 2020     4.0  google-cbrs-cpi-training  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>reviews</th>\n      <th>reviewers</th>\n      <th>date_reviews</th>\n      <th>rating</th>\n      <th>course_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Pretty dry, but I was able to pass with just t...</td>\n      <td>By Robert S</td>\n      <td>Feb 12, 2020</td>\n      <td>4.0</td>\n      <td>google-cbrs-cpi-training</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>would be a better experience if the video and ...</td>\n      <td>By Gabriel E R</td>\n      <td>Sep 28, 2020</td>\n      <td>4.0</td>\n      <td>google-cbrs-cpi-training</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Information was perfect! The program itself wa...</td>\n      <td>By Jacob D</td>\n      <td>Apr 08, 2020</td>\n      <td>4.0</td>\n      <td>google-cbrs-cpi-training</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A few grammatical mistakes on test made me do ...</td>\n      <td>By Dale B</td>\n      <td>Feb 24, 2020</td>\n      <td>4.0</td>\n      <td>google-cbrs-cpi-training</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Excellent course and the training provided was...</td>\n      <td>By Sean G</td>\n      <td>Jun 18, 2020</td>\n      <td>4.0</td>\n      <td>google-cbrs-cpi-training</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# working with a sample to start with, comment this out later\n",
    "df1 = df\n",
    "# df1 = df.iloc[0:100].copy()\n",
    "df1.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T19:50:39.396362100Z",
     "start_time": "2024-01-08T19:50:39.376646300Z"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "1.1 Perform pre-processing steps like Removing Punctuations, Numbers, and Special Characters, Stop Words in dataset. (1M)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "                                             reviews       reviewers  \\\n0  Pretty dry, but I was able to pass with just t...     By Robert S   \n1  would be a better experience if the video and ...  By Gabriel E R   \n2  Information was perfect! The program itself wa...      By Jacob D   \n3  A few grammatical mistakes on test made me do ...       By Dale B   \n4  Excellent course and the training provided was...       By Sean G   \n\n   date_reviews  rating                 course_id  \\\n0  Feb 12, 2020     4.0  google-cbrs-cpi-training   \n1  Sep 28, 2020     4.0  google-cbrs-cpi-training   \n2  Apr 08, 2020     4.0  google-cbrs-cpi-training   \n3  Feb 24, 2020     4.0  google-cbrs-cpi-training   \n4  Jun 18, 2020     4.0  google-cbrs-cpi-training   \n\n                                       clean_reviews  \n0  pretty dry able pass two complete watches im h...  \n1  would better experience video screen shots wou...  \n2  information perfect program little annoying wa...  \n3     grammatical mistakes test made double take bad  \n4  excellent course training provided detailed ea...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>reviews</th>\n      <th>reviewers</th>\n      <th>date_reviews</th>\n      <th>rating</th>\n      <th>course_id</th>\n      <th>clean_reviews</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Pretty dry, but I was able to pass with just t...</td>\n      <td>By Robert S</td>\n      <td>Feb 12, 2020</td>\n      <td>4.0</td>\n      <td>google-cbrs-cpi-training</td>\n      <td>pretty dry able pass two complete watches im h...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>would be a better experience if the video and ...</td>\n      <td>By Gabriel E R</td>\n      <td>Sep 28, 2020</td>\n      <td>4.0</td>\n      <td>google-cbrs-cpi-training</td>\n      <td>would better experience video screen shots wou...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Information was perfect! The program itself wa...</td>\n      <td>By Jacob D</td>\n      <td>Apr 08, 2020</td>\n      <td>4.0</td>\n      <td>google-cbrs-cpi-training</td>\n      <td>information perfect program little annoying wa...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A few grammatical mistakes on test made me do ...</td>\n      <td>By Dale B</td>\n      <td>Feb 24, 2020</td>\n      <td>4.0</td>\n      <td>google-cbrs-cpi-training</td>\n      <td>grammatical mistakes test made double take bad</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Excellent course and the training provided was...</td>\n      <td>By Sean G</td>\n      <td>Jun 18, 2020</td>\n      <td>4.0</td>\n      <td>google-cbrs-cpi-training</td>\n      <td>excellent course training provided detailed ea...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_text(text):\n",
    "    # Remove punctuations\n",
    "    try:\n",
    "        text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    except:\n",
    "        text = ['majorissue']\n",
    "    # Remove numbers\n",
    "    text = ''.join([i for i in text if not i.isdigit()])\n",
    "\n",
    "    # Remove special characters with space\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "\n",
    "    # Convert to lowercase and tokenize and remove stopwords\n",
    "    words = word_tokenize(text.lower())\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    return ' '.join(words)  # rejoin to make a string\n",
    "\n",
    "df1['clean_reviews'] = df1['reviews'].apply(preprocess_text)\n",
    "df1.head()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T20:00:22.036268400Z",
     "start_time": "2024-01-08T19:54:04.640993900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "      reviews           reviewers  date_reviews  rating            course_id  \\\n73671     NaN  By Christopher L J  Sep 26, 2020     5.0  computer-networking   \n73680     NaN       By Jerold K G  Jun 10, 2020     5.0  computer-networking   \n95147     NaN           By t. d k  Jun 27, 2020     5.0      ai-for-everyone   \n95152     NaN    By KODATHALA S V  May 29, 2020     5.0      ai-for-everyone   \n95172     NaN           By t. d k  Jun 27, 2020     5.0      ai-for-everyone   \n\n      clean_reviews  \n73671    majorissue  \n73680    majorissue  \n95147    majorissue  \n95152    majorissue  \n95172    majorissue  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>reviews</th>\n      <th>reviewers</th>\n      <th>date_reviews</th>\n      <th>rating</th>\n      <th>course_id</th>\n      <th>clean_reviews</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>73671</th>\n      <td>NaN</td>\n      <td>By Christopher L J</td>\n      <td>Sep 26, 2020</td>\n      <td>5.0</td>\n      <td>computer-networking</td>\n      <td>majorissue</td>\n    </tr>\n    <tr>\n      <th>73680</th>\n      <td>NaN</td>\n      <td>By Jerold K G</td>\n      <td>Jun 10, 2020</td>\n      <td>5.0</td>\n      <td>computer-networking</td>\n      <td>majorissue</td>\n    </tr>\n    <tr>\n      <th>95147</th>\n      <td>NaN</td>\n      <td>By t. d k</td>\n      <td>Jun 27, 2020</td>\n      <td>5.0</td>\n      <td>ai-for-everyone</td>\n      <td>majorissue</td>\n    </tr>\n    <tr>\n      <th>95152</th>\n      <td>NaN</td>\n      <td>By KODATHALA S V</td>\n      <td>May 29, 2020</td>\n      <td>5.0</td>\n      <td>ai-for-everyone</td>\n      <td>majorissue</td>\n    </tr>\n    <tr>\n      <th>95172</th>\n      <td>NaN</td>\n      <td>By t. d k</td>\n      <td>Jun 27, 2020</td>\n      <td>5.0</td>\n      <td>ai-for-everyone</td>\n      <td>majorissue</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[df1['clean_reviews'] == 'majorissue'].head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T20:00:22.142850900Z",
     "start_time": "2024-01-08T20:00:22.039268800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample change before and after cleaning\n",
      "0    Pretty dry, but I was able to pass with just t...\n",
      "Name: reviews, dtype: object\n",
      "\n",
      "\n",
      "0    pretty dry able pass two complete watches im h...\n",
      "Name: clean_reviews, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print('Sample change before and after cleaning')\n",
    "print(df1.iloc[0:1]['reviews'])\n",
    "print('\\n')\n",
    "print(df1.iloc[0:1]['clean_reviews'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T20:00:22.145850800Z",
     "start_time": "2024-01-08T20:00:22.130851800Z"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "1.2 Perform normalization by using Stemming or Lemmatization.  (1M)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "lm = WordNetLemmatizer()\n",
    "\n",
    "def apply_stemmer_lemmetizer(text):\n",
    "    words = word_tokenize(text)  # tokenising given string\n",
    "    stemmed_words = [ps.stem(word) for word in words]  # stemming given string\n",
    "    lemmatised_words = [lm.lemmatize(word) for word in stemmed_words]\n",
    "    return ' '.join(lemmatised_words)  # rejoin to make a string\n",
    "\n",
    "df1['lemmatised_reviews'] = df1['clean_reviews'].apply(apply_stemmer_lemmetizer)\n",
    "df1.head()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-01-08T20:00:22.147851100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Sample change before and after lemmitisation')\n",
    "print(df1.iloc[0:1]['clean_reviews'])\n",
    "print('\\n')\n",
    "print(df1.iloc[0:1]['lemmatised_reviews'])"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# uncomment to improve efficiency in large datasets\n",
    "# df1.drop('clean_reviews', axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "2 .Apply a POS tagging algorithm or utilize a pretrained POS tagger to assign POS tags to the words in the dataset.                                                                (3Marks)\n",
    "\n",
    "\n",
    "The Penn Treebank POS tag from nltk:\n",
    "\n",
    "NN: Noun, singular or mass\n",
    "NNS: Noun, plural\n",
    "VB: Verb, base form\n",
    "VBD: Verb, past tense\n",
    "VBG: Verb, gerund or present participle\n",
    "JJ: Adjective\n",
    "RB: Adverb\n",
    "PRP: Personal pronoun\n",
    "CD: Cardinal number (e.g., 'one', 'two')\n",
    "WP$: Possessive wh-pronoun  are few examples of pos tags"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def pos_tagging(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tags = nltk.pos_tag(tokens)\n",
    "    return tags\n",
    "\n",
    "df1['pos_tags'] = df1['lemmatised_reviews'].apply(pos_tagging)\n",
    "df1.head()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "3 .Identify the top N most common POS tags in the dataset, where N is a user-specified parameter  (1Mark)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hardcoded_pos_def = {'CC': 'conjunction, coordinating',\n",
    "                     'CD': 'numeral, cardinal',\n",
    "                     'DT': 'determiner',\n",
    "                     'EX': 'existential there',\n",
    "                     'FW': 'foreign word',\n",
    "                     'IN': 'preposition or conjunction, subordinating',\n",
    "                     'JJ': 'adjective or numeral, ordinal',\n",
    "                     'JJR': 'adjective, comparative',\n",
    "                     'JJS': 'adjective, superlative',\n",
    "                     'LS': 'list item marker',\n",
    "                     'MD': 'modal auxiliary',\n",
    "                     'NN': 'noun, common, singular or mass',\n",
    "                     'NNP': 'noun, proper, singular',\n",
    "                     'NNPS': 'noun, proper, plural',\n",
    "                     'NNS': 'noun, common, plural',\n",
    "                     'PDT': 'pre-determiner',\n",
    "                     'POS': 'genitive marker',\n",
    "                     'PRP': 'pronoun, personal',\n",
    "                     'PRP$': 'pronoun, possessive',\n",
    "                     'RB': 'adverb',\n",
    "                     'RBR': 'adverb, comparative',\n",
    "                     'RBS': 'adverb, superlative',\n",
    "                     'RP': 'particle',\n",
    "                     'SYM': 'symbol',\n",
    "                     'TO': '\"to\" as preposition or infinitive marker',\n",
    "                     'UH': 'interjection',\n",
    "                     'VB': 'verb, base form',\n",
    "                     'VBD': 'verb, past tense',\n",
    "                     'VBG': 'verb, present participle or gerund',\n",
    "                     'VBN': 'verb, past participle',\n",
    "                     'VBP': 'verb, present tense, not 3rd person singular',\n",
    "                     'VBZ': 'verb, present tense, 3rd person singular',\n",
    "                     'WDT': 'WH-determiner',\n",
    "                     'WP': 'WH-pronoun',\n",
    "                     'WP$': 'WH-pronoun, possessive',\n",
    "                     'WRB': 'Wh-adverb'}"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "count_dict = defaultdict(lambda: 0)\n",
    "for row in df1['pos_tags']:\n",
    "    for _, key in row:\n",
    "        count_dict[key] += 1\n",
    "\n",
    "counts_dict_final = dict(count_dict)\n",
    "counts_dict_df_ = pd.DataFrame(list(counts_dict_final.items()), columns=['pos_tags', 'occurrence_counts'])\n",
    "pos_def_df = pd.DataFrame(list(hardcoded_pos_def.items()), columns=['pos_tags', 'tag_definition'])\n",
    "\n",
    "counts_dict_df = pd.merge(counts_dict_df_, pos_def_df, on='pos_tags', how='left')\n",
    "\n",
    "N_max = counts_dict_df.shape[0]\n",
    "print('Total pos tags in data : {}'.format(N_max))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "N = int(input(\"Enter N for looking at top n pos tags, max N {}: \".format(N_max)))\n",
    "assert N<=N_max, 'Enter valid N <= N_max'\n",
    "\n",
    "counts_dict_df = counts_dict_df[['pos_tags', 'tag_definition', 'occurrence_counts']]\n",
    "counts_dict_df = counts_dict_df.sort_values(by='occurrence_counts', ascending=False)\n",
    "counts_dict_df.head(N)\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
