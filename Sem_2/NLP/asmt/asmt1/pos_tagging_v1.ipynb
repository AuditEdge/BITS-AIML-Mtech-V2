{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-08T20:10:25.339025700Z",
     "start_time": "2024-01-08T20:10:23.824814800Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\praka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\praka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\praka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\praka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package tagsets to\n",
      "[nltk_data]     C:\\Users\\praka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package tagsets is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "import re\n",
    "import random\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('tagsets')\n",
    "from nltk.corpus import reuters, stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from nltk import bigrams, FreqDist, ConditionalFreqDist\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1048309, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                             reviews       reviewers  \\\n0  Pretty dry, but I was able to pass with just t...     By Robert S   \n1  would be a better experience if the video and ...  By Gabriel E R   \n2  Information was perfect! The program itself wa...      By Jacob D   \n3  A few grammatical mistakes on test made me do ...       By Dale B   \n4  Excellent course and the training provided was...       By Sean G   \n\n   date_reviews  rating                 course_id  \n0  Feb 12, 2020     4.0  google-cbrs-cpi-training  \n1  Sep 28, 2020     4.0  google-cbrs-cpi-training  \n2  Apr 08, 2020     4.0  google-cbrs-cpi-training  \n3  Feb 24, 2020     4.0  google-cbrs-cpi-training  \n4  Jun 18, 2020     4.0  google-cbrs-cpi-training  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>reviews</th>\n      <th>reviewers</th>\n      <th>date_reviews</th>\n      <th>rating</th>\n      <th>course_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Pretty dry, but I was able to pass with just t...</td>\n      <td>By Robert S</td>\n      <td>Feb 12, 2020</td>\n      <td>4.0</td>\n      <td>google-cbrs-cpi-training</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>would be a better experience if the video and ...</td>\n      <td>By Gabriel E R</td>\n      <td>Sep 28, 2020</td>\n      <td>4.0</td>\n      <td>google-cbrs-cpi-training</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Information was perfect! The program itself wa...</td>\n      <td>By Jacob D</td>\n      <td>Apr 08, 2020</td>\n      <td>4.0</td>\n      <td>google-cbrs-cpi-training</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A few grammatical mistakes on test made me do ...</td>\n      <td>By Dale B</td>\n      <td>Feb 24, 2020</td>\n      <td>4.0</td>\n      <td>google-cbrs-cpi-training</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Excellent course and the training provided was...</td>\n      <td>By Sean G</td>\n      <td>Jun 18, 2020</td>\n      <td>4.0</td>\n      <td>google-cbrs-cpi-training</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Coursera_reviews.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T20:10:27.530067600Z",
     "start_time": "2024-01-08T20:10:25.340042400Z"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "1. Preprocess the dataset to convert it into a format that the algorithm can work with.\n",
    "\n",
    "Removing rows where column review is Null\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "                                             reviews       reviewers  \\\n0  Pretty dry, but I was able to pass with just t...     By Robert S   \n1  would be a better experience if the video and ...  By Gabriel E R   \n2  Information was perfect! The program itself wa...      By Jacob D   \n3  A few grammatical mistakes on test made me do ...       By Dale B   \n4  Excellent course and the training provided was...       By Sean G   \n\n   date_reviews  rating                 course_id  \n0  Feb 12, 2020     4.0  google-cbrs-cpi-training  \n1  Sep 28, 2020     4.0  google-cbrs-cpi-training  \n2  Apr 08, 2020     4.0  google-cbrs-cpi-training  \n3  Feb 24, 2020     4.0  google-cbrs-cpi-training  \n4  Jun 18, 2020     4.0  google-cbrs-cpi-training  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>reviews</th>\n      <th>reviewers</th>\n      <th>date_reviews</th>\n      <th>rating</th>\n      <th>course_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Pretty dry, but I was able to pass with just t...</td>\n      <td>By Robert S</td>\n      <td>Feb 12, 2020</td>\n      <td>4.0</td>\n      <td>google-cbrs-cpi-training</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>would be a better experience if the video and ...</td>\n      <td>By Gabriel E R</td>\n      <td>Sep 28, 2020</td>\n      <td>4.0</td>\n      <td>google-cbrs-cpi-training</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Information was perfect! The program itself wa...</td>\n      <td>By Jacob D</td>\n      <td>Apr 08, 2020</td>\n      <td>4.0</td>\n      <td>google-cbrs-cpi-training</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A few grammatical mistakes on test made me do ...</td>\n      <td>By Dale B</td>\n      <td>Feb 24, 2020</td>\n      <td>4.0</td>\n      <td>google-cbrs-cpi-training</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Excellent course and the training provided was...</td>\n      <td>By Sean G</td>\n      <td>Jun 18, 2020</td>\n      <td>4.0</td>\n      <td>google-cbrs-cpi-training</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# working with a sample to start with, comment this out later\n",
    "df1 = df.dropna(subset=['reviews']).copy()\n",
    "# df1 = df.dropna(subset=['reviews']).iloc[0:100].copy()\n",
    "df1.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T20:10:27.699840300Z",
     "start_time": "2024-01-08T20:10:27.531481800Z"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "1.1 Perform pre-processing steps like Removing Punctuations, Numbers, and Special Characters, Stop Words in dataset. (1M)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Remove punctuations\n",
    "    try:\n",
    "        text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    except:\n",
    "        text = ['majorissue']\n",
    "    # Remove numbers\n",
    "    text = ''.join([i for i in text if not i.isdigit()])\n",
    "\n",
    "    # Remove special characters with space\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "\n",
    "    # Convert to lowercase and tokenize and remove stopwords\n",
    "    words = word_tokenize(text.lower())\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    return ' '.join(words)  # rejoin to make a string\n",
    "\n",
    "df1['clean_reviews'] = df1['reviews'].apply(preprocess_text)\n",
    "df1.head()\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-01-08T20:10:27.684462900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df1[df1['clean_reviews'] == 'majorissue'].head()  # check if there has been any issue with tagging"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Sample change before and after cleaning')\n",
    "print(df1.iloc[0:1]['reviews'])\n",
    "print('\\n')\n",
    "print(df1.iloc[0:1]['clean_reviews'])"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "1.2 Perform normalization by using Stemming or Lemmatization.  (1M)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "lm = WordNetLemmatizer()\n",
    "\n",
    "def apply_stemmer_lemmetizer(text):\n",
    "    words = word_tokenize(text)  # tokenising given string\n",
    "    stemmed_words = [ps.stem(word) for word in words]  # stemming given string\n",
    "    lemmatised_words = [lm.lemmatize(word) for word in stemmed_words]\n",
    "    return ' '.join(lemmatised_words)  # rejoin to make a string\n",
    "\n",
    "df1['lemmatised_reviews'] = df1['clean_reviews'].apply(apply_stemmer_lemmetizer)\n",
    "df1.head()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Sample change before and after lemmitisation')\n",
    "print(df1.iloc[0:1]['clean_reviews'])\n",
    "print('\\n')\n",
    "print(df1.iloc[0:1]['lemmatised_reviews'])"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# uncomment to improve efficiency in large datasets\n",
    "# df1.drop('clean_reviews', axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "2 .Apply a POS tagging algorithm or utilize a pretrained POS tagger to assign POS tags to the words in the dataset.                                                                (3Marks)\n",
    "\n",
    "\n",
    "The Penn Treebank POS tag from nltk:\n",
    "\n",
    "NN: Noun, singular or mass\n",
    "NNS: Noun, plural\n",
    "VB: Verb, base form\n",
    "VBD: Verb, past tense\n",
    "VBG: Verb, gerund or present participle\n",
    "JJ: Adjective\n",
    "RB: Adverb\n",
    "PRP: Personal pronoun\n",
    "CD: Cardinal number (e.g., 'one', 'two')\n",
    "WP$: Possessive wh-pronoun  are few examples of pos tags"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def pos_tagging(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tags = nltk.pos_tag(tokens)\n",
    "    return tags\n",
    "\n",
    "df1['pos_tags'] = df1['lemmatised_reviews'].apply(pos_tagging)\n",
    "df1.head()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "3 .Identify the top N most common POS tags in the dataset, where N is a user-specified parameter  (1Mark)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hardcoded_pos_def = {'CC': 'conjunction, coordinating',\n",
    "                     'CD': 'numeral, cardinal',\n",
    "                     'DT': 'determiner',\n",
    "                     'EX': 'existential there',\n",
    "                     'FW': 'foreign word',\n",
    "                     'IN': 'preposition or conjunction, subordinating',\n",
    "                     'JJ': 'adjective or numeral, ordinal',\n",
    "                     'JJR': 'adjective, comparative',\n",
    "                     'JJS': 'adjective, superlative',\n",
    "                     'LS': 'list item marker',\n",
    "                     'MD': 'modal auxiliary',\n",
    "                     'NN': 'noun, common, singular or mass',\n",
    "                     'NNP': 'noun, proper, singular',\n",
    "                     'NNPS': 'noun, proper, plural',\n",
    "                     'NNS': 'noun, common, plural',\n",
    "                     'PDT': 'pre-determiner',\n",
    "                     'POS': 'genitive marker',\n",
    "                     'PRP': 'pronoun, personal',\n",
    "                     'PRP$': 'pronoun, possessive',\n",
    "                     'RB': 'adverb',\n",
    "                     'RBR': 'adverb, comparative',\n",
    "                     'RBS': 'adverb, superlative',\n",
    "                     'RP': 'particle',\n",
    "                     'SYM': 'symbol',\n",
    "                     'TO': '\"to\" as preposition or infinitive marker',\n",
    "                     'UH': 'interjection',\n",
    "                     'VB': 'verb, base form',\n",
    "                     'VBD': 'verb, past tense',\n",
    "                     'VBG': 'verb, present participle or gerund',\n",
    "                     'VBN': 'verb, past participle',\n",
    "                     'VBP': 'verb, present tense, not 3rd person singular',\n",
    "                     'VBZ': 'verb, present tense, 3rd person singular',\n",
    "                     'WDT': 'WH-determiner',\n",
    "                     'WP': 'WH-pronoun',\n",
    "                     'WP$': 'WH-pronoun, possessive',\n",
    "                     'WRB': 'Wh-adverb'}"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "count_dict = defaultdict(lambda: 0)\n",
    "for row in df1['pos_tags']:\n",
    "    for _, key in row:\n",
    "        count_dict[key] += 1\n",
    "\n",
    "counts_dict_final = dict(count_dict)\n",
    "counts_dict_df_ = pd.DataFrame(list(counts_dict_final.items()), columns=['pos_tags', 'occurrence_counts'])\n",
    "pos_def_df = pd.DataFrame(list(hardcoded_pos_def.items()), columns=['pos_tags', 'tag_definition'])\n",
    "\n",
    "counts_dict_df = pd.merge(counts_dict_df_, pos_def_df, on='pos_tags', how='left')\n",
    "\n",
    "N_max = counts_dict_df.shape[0]\n",
    "print('Total pos tags in data : {}'.format(N_max))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "N = int(input(\"Enter N for looking at top n pos tags, max N {}: \".format(N_max)))\n",
    "assert N<=N_max, 'Enter valid N <= N_max'\n",
    "\n",
    "counts_dict_df = counts_dict_df[['pos_tags', 'tag_definition', 'occurrence_counts']]\n",
    "counts_dict_df = counts_dict_df.sort_values(by='occurrence_counts', ascending=False)\n",
    "counts_dict_df.head(N)\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
